{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy Prediction Exercise\n",
    "\n",
    "Please reference the `READ.ME` before getting started\n",
    "\n",
    "## Goal\n",
    "\n",
    "Create a model that can accurately (+/- 10%) predict the energy consumption on December 31st using nothing but energy data and publicly accessible weather data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import\n",
    "\n",
    "Import the data and convert the csv data into a Pandas dataframe. Then plot using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "raw_df = pd.read_csv('./data/cleaned_data.csv')\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphical View\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.reset_index().plot.scatter(x = 'index',  y='consumption')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.tail(24).reset_index().plot.scatter(x = 'index',  y='consumption')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minor Transformations and Cleanup\n",
    "\n",
    "1. Create a new `timestamp` column that transforms the stringified timestamp to python datetime objects.\n",
    "2. Set the new column to the dataframes index column.\n",
    "3. Drop the old `Timestamp` column as it is no longer needed.\n",
    "4. Add a new `hour` and `dow` (day of week) column for additional timeframe analysis using built in pandas methods\n",
    "5. Duplicate the dataframe for a training set\n",
    "6. Remove the last day's data (we don't want to train the models with the data we're trying to predict!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_df['timestamp'] = pd.to_datetime(raw_df['Timestamp'])\n",
    "raw_df.drop(columns=['Timestamp'], inplace=True)\n",
    "raw_df.set_index('timestamp', inplace=True)\n",
    "\n",
    "raw_df['hour'] = raw_df.index.hour\n",
    "raw_df['dow'] = raw_df.index.dayofweek\n",
    "\n",
    "df = raw_df.copy()\n",
    "df.drop(df.tail(24).index,inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphical Comparison\n",
    "\n",
    "Plot Hour, DoW, Outdoor Air Temp, CDD, HDD vs Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "figure, axis = plt.subplots(3, 2)\n",
    "axis[0, 0].scatter(df.index, df['consumption'])\n",
    "axis[0, 0].set_title('Time vs Consumption')\n",
    "axis[0, 1].scatter(df['hour'], df['consumption'])\n",
    "axis[0, 1].set_title('Hour vs Consumption')\n",
    "axis[1, 0].scatter(df['dow'], df['consumption'])\n",
    "axis[1, 0].set_title('Day of Week vs Consumption')\n",
    "axis[1, 1].scatter(df['cdd'], df['consumption'])\n",
    "axis[1, 1].set_title('CDD vs Consumption')\n",
    "axis[2, 0].scatter(df['hdd'], df['consumption'])\n",
    "axis[2, 0].set_title('HDD vs Consumption')\n",
    "axis[2, 1].scatter(df['avg_tmp'], df['consumption'])\n",
    "axis[2, 1].set_title('Avg Temp vs Consumption')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Start Modeling!!\n",
    "\n",
    "We're going to start with a simple regression model which is essentially finding the line of best fit for the data.\n",
    "\n",
    "Our first variable we're going to try and fit is Hour vs Consumption using the Stat Models library.\n",
    "\n",
    "After initial testing, we are going to use a 5th degree polynomial which we can create with Scikit-learn.\n",
    "\n",
    "Our steps include:\n",
    "1. Make a fresh copy of the dataframe that we can manipulate\n",
    "3. Apply our 5th degree polynomial by creating 5 new columns in the dataframe and applying the scikit-learn PolynomialFeatures class\n",
    "4. Separate out our data into independent (feature in ml lingo) and dependent (label in ml lingo) variables\n",
    "\n",
    "Let's check out what the independent data looks like!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "hour_df = df.copy()\n",
    "\n",
    "hour_poly_degree = 5\n",
    "hour_df[[f'hour:poly={i}' for i in range(0, hour_poly_degree + 1)]] = PolynomialFeatures(hour_poly_degree).fit_transform(df[['hour']])\n",
    "\n",
    "hour_x = hour_df.drop(columns=['hour', 'dow', 'cdd', 'hdd', 'avg_tmp', 'consumption'])\n",
    "y = df['consumption']\n",
    "\n",
    "hour_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Then we fit our data using statsmodels Linear Regression Ordinary Least Squares model\n",
    "\n",
    "Next lets checkout the summary statistics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_model = sm.OLS(y, hour_x).fit()\n",
    "hour_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the Results\n",
    "\n",
    "We are interested in the R-Squared and P>|t| values above\n",
    "\n",
    "The R-Squared is very important. Utilties and ESCO companies follow IPMVP which is the International Performance Measurement and Verification Protocol to verify energy savings. You can learn more about IPMVP [HERE](https://evo-world.org/en/products-services-mainmenu-en/protocols/ipmvp) however, the important thing to know is we need a r-squared value greater than 0.7 to be deemed statistically significant.\n",
    "\n",
    "The p-value is also very important when looking at the summary statistics. This value can tell us weather the independent variable had a statistically significant impact on the model. Typically any value less than 0.05 is considered statistically significant. If the value is greater than 0.05 you typically drop that variable and refit the model without the bad variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see how this model looks!\n",
    "\n",
    "Even though the R-Squared value is below 0.7, lets still take a look and see how this model did!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Hourly Predicted Model\n",
    "hours = hour_x.copy().iloc[:24,:]\n",
    "hours['Predicted Consumption'] = hour_model.predict(hours)\n",
    "hours['hour'] = hours.index.hour\n",
    "\n",
    "plt.scatter(df['hour'], df['consumption'])\n",
    "plt.title('Hour vs Consumption')\n",
    "plt.plot(hours['hour'], hours['Predicted Consumption'], color='red')\n",
    "plt.show()\n",
    "\n",
    "year_df = hour_x.copy()\n",
    "year_df['Predicted Consumption'] = hour_model.predict(year_df)\n",
    "year_df['hour'] = year_df.index.hour\n",
    "plt.scatter(df.index, df['consumption'])\n",
    "plt.plot(year_df.index, year_df['Predicted Consumption'], color='red')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to do the other variables look?\n",
    "\n",
    "So I ran the numbers on each of the variables and the results are as follows:\n",
    "\n",
    "- DoW is best with a 5th degree polynomial applied\n",
    "- CDD and HDD work best with no polynomial applied (they are suppose to be linear)\n",
    "- Avg Temp works best with a 6th degree polynomial applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DoW Model\n",
    "dow_poly_degree = 5\n",
    "dow_df = df.copy()\n",
    "dow_df[[f'hour:poly={i}' for i in range(0, dow_poly_degree + 1)]] = PolynomialFeatures(dow_poly_degree).fit_transform(df[['dow']])\n",
    "dow_x = dow_df.drop(columns=['hour', 'dow', 'cdd', 'hdd', 'avg_tmp', 'consumption'])\n",
    "dow_x = sm.add_constant(dow_x)\n",
    "y = df['consumption']\n",
    "dow_model = sm.OLS(y, dow_x).fit()\n",
    "\n",
    "# CDD Model\n",
    "cdd_df = df.copy()\n",
    "cdd_df = cdd_df[(cdd_df.cdd != 0)]\n",
    "cdd_x = cdd_df.drop(columns=['hour', 'dow', 'hdd', 'avg_tmp', 'consumption'])\n",
    "cdd_x = sm.add_constant(cdd_x)\n",
    "y = cdd_df['consumption']\n",
    "cdd_model = sm.OLS(y, cdd_x).fit()\n",
    "\n",
    "# HDD Model\n",
    "hdd_df = df.copy()\n",
    "hdd_df = hdd_df[(hdd_df.hdd != 0)]\n",
    "hdd_x = hdd_df.drop(columns=['hour', 'dow', 'cdd', 'avg_tmp', 'consumption'])\n",
    "hdd_x = sm.add_constant(hdd_x)\n",
    "y = hdd_df['consumption']\n",
    "hdd_model = sm.OLS(y, hdd_x).fit()\n",
    "\n",
    "# Avg Temp Model\n",
    "avg_tmp_poly_degree = 6\n",
    "avg_tmp_df = df.copy()\n",
    "avg_tmp_df[[f'hour:poly={i}' for i in range(0, avg_tmp_poly_degree + 1)]] = PolynomialFeatures(avg_tmp_poly_degree).fit_transform(df[['avg_tmp']])\n",
    "avg_tmp_x = avg_tmp_df.drop(columns=['hour', 'dow', 'cdd', 'hdd', 'avg_tmp', 'consumption'])\n",
    "avg_tmp_x = sm.add_constant(avg_tmp_x)\n",
    "y = df['consumption']\n",
    "avg_temp_model = sm.OLS(y, avg_tmp_x).fit()\n",
    "\n",
    "# Predict Individual Models\n",
    "\n",
    "# Predict DoW Predicted Model\n",
    "dow = dow_x.copy().iloc[:(10 * 24),:].iloc[::24, :].iloc[3:]\n",
    "dow['Predicted Consumption'] = dow_model.predict(dow)\n",
    "dow['dow'] = dow.index.dayofweek\n",
    "\n",
    "# Predict CDD Model\n",
    "cdd = cdd_x.copy()\n",
    "cdd['Predicted Consumption'] = cdd_model.predict(cdd)\n",
    "cdd['cdd'] = df['cdd']\n",
    "\n",
    "# Show HDD Model\n",
    "hdd = hdd_x.copy()\n",
    "hdd['Predicted Consumption'] = hdd_model.predict(hdd)\n",
    "hdd['hdd'] = df['hdd']\n",
    "\n",
    "# Show Avg Temp Model\n",
    "temp = avg_tmp_x.copy()\n",
    "temp['Predicted Consumption'] = avg_temp_model.predict(temp)\n",
    "temp['avg_tmp'] = df['avg_tmp']\n",
    "\n",
    "# Show all models on graphs\n",
    "figure, axis = plt.subplots(2, 2)\n",
    "axis[0, 0].scatter(df['dow'], df['consumption'])\n",
    "axis[0, 0].plot(dow['dow'], dow['Predicted Consumption'], color='red')\n",
    "axis[0, 0].set_title('Day of Week vs Consumption')\n",
    "axis[0, 1].scatter(df['cdd'], df['consumption'])\n",
    "axis[0, 1].plot(cdd['cdd'], cdd['Predicted Consumption'], color='red')\n",
    "axis[0, 1].set_title('CDD vs Consumption')\n",
    "axis[1, 0].scatter(df['hdd'], df['consumption'])\n",
    "axis[1, 0].plot(hdd['hdd'], hdd['Predicted Consumption'], color='red')\n",
    "axis[1, 0].set_title('HDD vs Consumption')\n",
    "axis[1, 1].scatter(df['avg_tmp'], df['consumption'])\n",
    "axis[1, 1].set_title('Avg Temp vs Consumption')\n",
    "axis[1, 1].plot(temp['avg_tmp'], temp['Predicted Consumption'], color='red')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Improve it!\n",
    "\n",
    "Next let's try adding in some more variables! Let's add CDD and HDD to the hourly variable and see if we can make it any better.\n",
    "\n",
    "Let's take a peak at the data after we add in the extra independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_poly_degree = 5\n",
    "new_df = df.copy()\n",
    "new_df[[f'hour:poly={i}' for i in range(0, hour_poly_degree + 1)]] = PolynomialFeatures(hour_poly_degree).fit_transform(new_df[['hour']])\n",
    "\n",
    "hour_cdd_hdd_x = new_df.drop(columns=['dow', 'hour', 'avg_tmp', 'consumption'])\n",
    "y = df['consumption']\n",
    "\n",
    "hour_cdd_hdd_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's finish it off and see the model!\n",
    "\n",
    "Note that get a more readable graph, the consumption values are averaged by day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_cdd_hdd_model = sm.OLS(y, hour_cdd_hdd_x).fit()\n",
    "\n",
    "temp_df = df.copy()\n",
    "temp_df['Predicted Consumption'] = hour_cdd_hdd_model.predict(hour_cdd_hdd_x)\n",
    "ndf = temp_df.resample('D').mean()\n",
    "plt.scatter(ndf.index, ndf['consumption'])\n",
    "plt.title('Consumption vs Time')\n",
    "plt.xlabel('Time (daily avg)')\n",
    "plt.ylabel('Consumption (kWh)')\n",
    "plt.plot(ndf.index, ndf['Predicted Consumption'], color='red')\n",
    "\n",
    "hour_cdd_hdd_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does this model meet our Goal?\n",
    "\n",
    "Remember our goal was to be within +/- 10% of the actual consumption value for December 31st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predicted_df = raw_df.copy()\n",
    "predicted_df[[f'hour:poly={i}' for i in range(0, 5 + 1)]] = PolynomialFeatures(5).fit_transform(predicted_df[['hour']])\n",
    "final_model_x = predicted_df.drop(columns=['dow', 'hour', 'avg_tmp', 'consumption'])\n",
    "\n",
    "predicted_df['Predicted Consumption'] = hour_cdd_hdd_model.predict(final_model_x)\n",
    "predicted_interval = predicted_df.iloc[-24:]\n",
    "\n",
    "plt.scatter(predicted_interval.index, predicted_interval['consumption'])\n",
    "plt.title('Consumption vs Time')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Consumption (kWh)')\n",
    "plt.plot(predicted_interval.index, predicted_interval['Predicted Consumption'], color='red')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's checkout the numbers (fingers crossed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "consumption_df = predicted_interval[['consumption', 'Predicted Consumption']]\n",
    "actual = consumption_df['consumption'].sum()\n",
    "predicted = consumption_df['Predicted Consumption'].sum()\n",
    "percent_diff = ((abs(actual - predicted)) / ((actual + predicted) / 2)) * 100\n",
    "\n",
    "display(consumption_df)\n",
    "display('Totals')\n",
    "display(consumption_df.sum())\n",
    "display(f\"Difference: {actual-predicted}\")\n",
    "display(f\"% Difference: {round(percent_diff, 2)}%\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "06434aaa4b24f4d8bdd40474f12473a4a0ab89e2924cc047ae0ff5f0717e2c81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
